---
title: "SURV727 Final Project"
author: "Akari Oya, Zhouer Wang"
format: html
---
# Github link: <https://github.com/ZuorW/SURV727.git>


```{r, include = FALSE}
library(tidyverse)
```


## Proposal:
weather data vs gtrends data for seasonal depression-related words

## Open Meteo API
```{r}
# Load necessary package
library(openmeteo)

# see which weather variables we have data for (not a complete list)
weather_variables()

# Pulling one city's dataset
# we probably can't use Ann Arbor since we couldn't locate gtrends to Ann Arbor
# cities we could use = 

weather <- weather_history("Detroit",
  start = "2017-12-01",
  end = "2023-12-01",
  daily = "daylight_duration") # pulling for dayling duration

# Check data
str(weather)
head(weather) # daylight seems to be in seconds

```

```{r}
# Manipulate/clean dataset

# Rename columns for ease of reading
weather <- weather %>% 
  rename(daylight_sec = daily_daylight_duration)

# Add column for city
weather$city <- "Detroit"

# Add column for daylight by hour
weather$daylight_hrs <- weather$daylight_sec/ 3600
weather$year <- substr(weather$date, 1,4)

# Add weekly average daylight column so it matches gtrends
weather <- weather %>% 
  mutate(week = week(ymd(date))) %>% 
  group_by(week) %>% 
  mutate(weekavg_hrs = mean(daylight_hrs))

# Reorder columns
colnames(weather)
col_order <- c("date", "year", "city", "daylight_sec",
               "daylight_hrs", "weekavg_hrs")
weather <- weather[, col_order]

head(weather)
```

```{r}
# Create loop to grab all cities of interest

# First, create list of cities of interest
cities <- c("Ann Arbor", "Lansing", "Grand Rapids", "Kalamazoo")
col_order2 <- c("city", "daylight_sec",
               "daylight_hrs", "weekavg_hrs")

# Use weather_history() to get historical weather data
for(i in cities) {
other_weather <- weather_history(i,
  start = "2017-12-01",
  end = "2023-12-01",
  daily = "daylight_duration")

  other_weather <- other_weather %>% 
    rename(daylight_sec = daily_daylight_duration) #rename column

  other_weather$daylight_hrs <- other_weather$daylight_sec / 3600 #create daylight by hour column
  other_weather$city <- i # add city column
  other_weather$year <- substr(weather$date, 1,4) #create year column
  
  other_weather <- other_weather %>% 
    mutate(week = week(ymd(date))) %>% #add week column
    group_by(week) %>%  
    mutate(weekavg_hrs = mean(daylight_hrs)) #compute weekly average daylight hours

  other_weather_nd <- subset(other_weather, select = -c(date, year, week)) #remove repetitive columns
  
  other_weather_nd <- other_weather_nd[, col_order2]
  
  weather <- cbind(weather, other_weather_nd) # combine datasets
}

head(weather)

```





For gtrends
```{r}

library(gtrendsR)
res <- gtrends(c("antidepressants", "depression"), 
               geo = "US-MI", 
               time = "2020-01-01 2020-12-31", 
               low_search_volume = TRUE)
plot(res)

#transform the data.frame into tibble
rest_city <- tibble(res$interest_by_city)

#reshape the data & sort loans column in descending order
city_ranking <- rest_city %>%
  pivot_wider(names_from = keyword, 
              values_from = hits) %>%
  arrange(., desc(loans))

#display first few rows of the ranking to find the highest searched
head(city_ranking)
```

