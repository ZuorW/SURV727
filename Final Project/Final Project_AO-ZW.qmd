---
title: "SURV727 Final Project"
author: "Akari Oya, Zhouer Wang"
format: html
---

# Github link: <https://github.com/ZuorW/SURV727.git>

```{r, include = FALSE}
library(tidyverse)
```


# Question:
Are there any patterns in depression-related Google searches by weather in Michigan?

## Open Meteo API
For daylight duration
```{r}
# Load necessary package
library(openmeteo)

# see which weather variables we have data for (not a complete list)
weather_variables()

# Test code with one city first
weather_daylight <- weather_history("Detroit",
  start = "2017-12-01",
  end = "2023-12-01",
  daily = "daylight_duration") # pulling for dayling duration

# Check data
str(weather_daylight)
head(weather_daylight) # daylight seems to be in seconds
```

```{r}
# Manipulate/clean dataset with one city first

# Rename columns for ease of reading
weather_daylight <- weather_daylight %>% 
  rename(daylight_sec = daily_daylight_duration)

# Add column for city
weather_daylight$city <- "Detroit"

# Add column for daylight by hour
weather_daylight$daylight_hrs <- weather_daylight$daylight_sec/ 3600
weather_daylight$year <- substr(weather_daylight$date, 1,4)

# Add weekly average daylight column so it matches gtrends
weather_daylight <- weather_daylight %>% 
  mutate(week = week(ymd(date))) %>% 
  group_by(week) %>% 
  mutate(weekavg_hrs = mean(daylight_hrs))

# Reorder columns
colnames(weather_daylight)
col_order <- c("date", "year", "week", "city", "daylight_hrs", "weekavg_hrs")
weather_daylight <- weather_daylight[, col_order]

head(weather_daylight)
```

```{r}
# Create loop to grab all cities of interest

# First, create list of cities of interest
cities <- c("Detroit", "Ann Arbor", "Lansing", "Grand Rapids", "Kalamazoo")

# Create object to store each city as a data frame
daylight_dataframes <- list()

# Use weather_history() to get historical weather data
for(i in cities) {
weather_daylight <- weather_history(i,
  start = "2017-12-01",
  end = "2023-12-01",
  daily = "daylight_duration")

  weather_daylight <- weather_daylight %>% 
    rename(daylight_sec = daily_daylight_duration) #rename column
  weather_daylight$daylight_hrs <- weather_daylight$daylight_sec / 3600 #create daylight by hour column
  weather_daylight$city <- i # add city column
  weather_daylight$year <- substr(weather_daylight$date, 1,4) #create year column
  
  weather_daylight <- weather_daylight %>% 
    mutate(week = week(ymd(date))) %>% #add week column
    group_by(week) %>%  
    mutate(weekavg_hrs = mean(daylight_hrs)) #compute weekly average daylight hours

  weather_daylight <- weather_daylight[, col_order] #reorder columns
  daylight_dataframes[[i]] <- weather_daylight #add new data frame to list
}

head(daylight_dataframes)
```


Same as above but for snow fall:
```{r}
# Test code with one city first
weather_snow <- weather_history("Detroit",
  start = "2017-12-01",
  end = "2023-12-01",
  daily = "snowfall_sum") # unit is inches

# Check data
str(weather_snow)
head(weather_snow)
```

```{r}
# Create loop to grab all cities of interest for snow fall

# First, create list of cities of interest
col_order_snow2 <- c("date", "week", "city", "daily_snow", "weekavg_snow")

# Create object to store each city as a data frame
snow_dataframes <- list()

# Use weather_history() to get historical weather data
for(i in cities) {
weather_snow <- weather_history(i,
  start = "2017-12-01",
  end = "2023-12-01",
  daily = "snowfall_sum")

  weather_snow <- weather_snow %>% 
    rename(daily_snow = daily_snowfall_sum) #rename column
  weather_snow$city <- i # add city column
  weather_snow$year <- substr(weather_snow$date, 1,4) #create year column
  
  weather_snow <- weather_snow %>% 
    mutate(week = week(ymd(date))) %>% #add week column
    group_by(week) %>%  
    mutate(weekavg_snow = mean(daily_snow)) #compute weekly average daylight hours

  weather_snow <- weather_snow[, col_order_snow2] #reorder columns
  snow_dataframes[[i]] <- weather_snow #add new data frame to list
}

head(snow_dataframes)
```

Combining city data
```{r}
# Combine all city dataframes into one long dataframe
daylight_long <- bind_rows(daylight_dataframes)
head(daylight_long)

# Combine all city dataframes into one long dataframe
snow_long <- bind_rows(snow_dataframes)
head(snow_long)
```


Combining daylight and snowfall data
```{r}
weather <- merge(daylight_long, snow_long, by = c("date", "week", "city"))
head(weather)
colnames(weather) 
```


Making plots for weather data
```{r}
ggplot(data = weather, aes(x= date)) +
  geom_line(aes(y = daily_snow, color = city))

ggplot(data = weather, aes(x = date)) +
  geom_line(aes(y = daylight_hrs, color = city)) +
   scale_x_date(limits = as.Date(c("2018-01-01","2018-12-31"))) +
   ggtitle("2018 zoom example")

ggplot(data = weather, aes(x = date)) +
  geom_line(aes(y = weekavg_snow, color = city)) +
   scale_x_date(limits = as.Date(c("2018-01-01","2018-12-31"))) +
   ggtitle("2018 zoom example")
```

```{r}
weather %>% 
  group_by(year) %>% 
  summarise(mean_daily_snow = mean(daily_snow),
            min_daily_snow = min(daily_snow),
            max_daily_snow = max(daily_snow))
weather %>% 
  group_by(year, city) %>% 
  summarise(mean_daily_snow = mean(daily_snow),
            min_daily_snow = min(daily_snow),
            max_daily_snow = max(daily_snow))

weather %>% 
  group_by(year, city) %>% 
  summarise(mean_daylight = mean(daylight_hrs),
            min_daylight = min(daylight_hrs),
            max_daylight = max(daylight_hrs))
```




Google trends data
```{r}
gtrends <- read.csv("/Users/akarioya/temp/SURV727/Final Project/17_23_SearchFreqeuncies.csv", skip = 2) #allows third row to be column names
colnames(gtrends)
```

```{r}
# Clean gtrends data to match weather data
# Reorder date
gtrends <- gtrends %>% 
  mutate(date = as.Date(Week, format = "%m/%d/%y")) %>% 
  select(-c(Week)) %>% #remove old Week column
  rename(light_therapy = light.therapy...Michigan.) %>% 
  rename(winter_blues = winter.blues...Michigan.) %>% 
  rename(SAD = Seasonal.affective.disorder...Michigan.) %>% 
  relocate(date, .before = light_therapy) #reorder columns

head(gtrends)
```



















For gtrends (later)
```{r}

library(gtrendsR)
res <- gtrends(c("light therapy", "seasonal affective disorder", "winter blues"), 
               geo = "US-MI", 
               time = "2017-12-01 2023-12-01", 
               low_search_volume = TRUE)
plot(res)

#transform the data.frame into tibble
rest_city <- tibble(res$interest_by_city)

#reshape the data & sort loans column in descending order
city_ranking <- rest_city %>%
  pivot_wider(names_from = keyword, 
              values_from = hits) %>%
  arrange(., desc(loans))

#display first few rows of the ranking to find the highest searched
head(city_ranking)
```
# since my gtrends is still not working well, i will use the downloaded data for the presentation. (Will work on pulling directly from gtrends after presentation).
library(ggplot2)

# read in the data from csv files stored in this repo
# head(trends)
trends$Week = as.Date(trends$Week, "%m/%d/%y") # convert original data to a R readable format

ggplot(data = trends, aes(x= Week, group = 1))+
  geom_line(aes(y =light_therapy, color = "Light Therapy"), size =1.2)+
  geom_line(aes(y =winter_blues, color = "Winter Blues"),size =1.2) +
  geom_line(aes(y =Seasonal_affective_disorder, color = "Seasonal Affective Disorder"), size =1.2)
# we could use this plot (A) to see the overal trend across years

# then zoom to a subsection of A to see the data from 2017, plot (B)
#head(X17)
X17$Week = as.Date(X17$Week, "%m/%d/%y") # use this to transform the date to R readable ones

ggplot(data = X17, aes(x= Week, group = 1))+
  geom_line(aes(y =Seasonal_affective_disorder, color = "Seasonal Affective Disorder"), size =1.2) +
  geom_line(aes(y =winter_blues, color = "Winter Blues"),size =1.2) +
  geom_line(aes(y =light_therapy, color = "Light Therapy"), size =1.2) +
  theme(axis.text.x = element_text(size=10))
