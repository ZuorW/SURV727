---
title: "SURV727 Final Project Report"
author: "Akari Oya, Zhuoer Wang"
format: pdf
bibliography: ref.bib
---

# Github link: <https://github.com/ZuorW/SURV727.git>

```{r, include = FALSE}
library(tidyverse)
library(openmeteo)
library(gtrendsR)
```

# Introduction:

### Literature Revieiw

Seasonal Affective Disorder (SAD) is a form of depression that typically appears during fall and winter, as the amount of natural sunlight decreases. This mood disorder affects millions of people across the globe, with varying degrees of severity. It is associated with a range of symptoms, including low energy, sleep problems, and even suicidal ideation in more severe cases [@PsychiatryOrg]. Remarkably, populations residing in the northern U.S. regions, such as Michigan, where winters are acute and sunlight is often sparse, observe a higher prevalence of SAD.

One of the most notable exacerbating factors for SAD is weather, specifically less sunlight and increased snowfall. Prior studies have suggested a possible correlation, with many individuals reporting a decline in their moods [@Postolache2011] or mental health during periods of increased snowfall or reduced sunlight [@Langer2023]. Hence, understanding the relationship between weather patterns and SAD prevalence could yield meaningful insights for health professionals, guiding the development of targeted interventions to mitigate the impact of SAD.

In order to gauge the public's interest in SAD, we propose the use of Google Trends data. Google Trends provides "access to a largely unfiltered sample of actual search requests made to Google" that is anonymized, categorized, and aggregated. This tools allows us to examine interest in a particular topic from at the city, state, or country level through search frequencies of keywords [@GoogleTrends].

While there is a body of literature exploring different facets of SAD, there is a lack of research specifically focused on assessing the relationship between weather patterns and SAD. The novel approach of examining depression-related Google search terms in relation to weather conditions in Michigan further emphasizes the uniqueness and significance of our exploratory study.

### Research Question:

Are there any patterns in depression-related Google searches by weather in Michigan?


# Data

To understand potential patterns in depression-related Google searches by weather in Michigan, we collected weather data and Google search frequencies for SAD-related search terms using APIs.

### Open Meteo API

Historical weather data was obtained through the publicly available Open-Meteo API (https://open-meteo.com). We used the R package "openmeteo" to query daily total snowfall and daily daylight duration data between December 1, 2017 to December 1, 2023 from the following cities to represent different parts of Michigan (excluding the Upper Peninsula): Ann Arbor, Detroit, Lansing, Grand Rapids, and Kalamazoo. Each row in the queried dataset is a day of the year with each day's weather variables as columns. Below is a snippet of the datset. The main variables of interest are snowfall and daylight duration. Daylight duration is a numeric variable representing the amount of seconds that daylight was present in each day. We converted the unit into hours, and daylight duration ranged from 9.00 to 15.36 hours with a mean of 12.24 hours across all years and cities. 

```{r, include = FALSE}
# For daylight duration

# Load necessary package
library(openmeteo)

# see which weather variables we have data for (not a complete list)
weather_variables()

# Test code with one city first
weather_daylight <- weather_history("Detroit",
  start = "2017-12-01",
  end = "2023-12-01",
  daily = "daylight_duration") # pulling for dayling duration

# Check data
str(weather_daylight)
head(weather_daylight) # unit seems in seconds
```

```{r, include = FALSE}
# Manipulate/clean dataset with one city first

# Rename columns for ease of reading
weather_daylight <- weather_daylight %>% 
  rename(daylight_sec = daily_daylight_duration)

# Add column for city
weather_daylight$city <- "Detroit"

# Add column for daylight by hour
weather_daylight$daylight_hrs <- weather_daylight$daylight_sec/ 3600
weather_daylight$year <- substr(weather_daylight$date, 1,4)

# Add weekly average daylight column so it matches gtrends
weather_daylight <- weather_daylight %>% 
  mutate(week = week(ymd(date))) %>% 
  group_by(week) %>% 
  mutate(weekavg_hrs = mean(daylight_hrs))

# Reorder columns
colnames(weather_daylight)
col_order <- c("date", "year", "week", "city", "daylight_hrs", "weekavg_hrs")
weather_daylight <- weather_daylight[, col_order]

head(weather_daylight)
```

```{r, include = FALSE}
# Create loop to grab all cities of interest

# First, create list of cities of interest
cities <- c("Detroit", "Ann Arbor", "Lansing", "Grand Rapids", "Kalamazoo")

# Create object to store each city as a data frame
daylight_dataframes <- list()

# Use weather_history() to get historical weather data
for(i in cities) {
weather_daylight <- weather_history(i,
  start = "2017-12-01",
  end = "2023-12-01",
  daily = "daylight_duration")

  weather_daylight <- weather_daylight %>% 
    rename(daylight_sec = daily_daylight_duration) #rename column
  weather_daylight$daylight_hrs <- weather_daylight$daylight_sec / 3600 #create daylight by hour column
  weather_daylight$city <- i # add city column
  weather_daylight$year <- substr(weather_daylight$date, 1,4) #create year column
  
  weather_daylight <- weather_daylight %>% 
    mutate(week = week(ymd(date))) %>% #add week column
    group_by(week) %>%  
    mutate(weekavg_hrs = mean(daylight_hrs)) #compute weekly average daylight hours

  weather_daylight <- weather_daylight[, col_order] #reorder columns
  daylight_dataframes[[i]] <- weather_daylight #add new data frame to list
}
```

```{r, echo=FALSE}
head(daylight_dataframes$Detroit, n = 3)
```

Snowfall is a numeric variable indicating the total amount of snowfall in millimeters for each day. The average snowfall between 2018 and 2023 was 0.26 millimeters with a maximum of 25.55 millimeters.

```{r, include = FALSE}
# Snowfall Data

# Test code with one city first
weather_snow <- weather_history("Detroit",
  start = "2017-12-01",
  end = "2023-12-01",
  daily = "snowfall_sum") # unit is inches

# Check data
str(weather_snow)
head(weather_snow)
```

```{r, include = FALSE}
# Create loop to grab all cities of interest for snow fall

# First, create list of cities of interest
col_order_snow2 <- c("date", "week", "city", "daily_snow", "weekavg_snow")

# Create object to store each city as a data frame
snow_dataframes <- list()

# Use weather_history() to get historical weather data
for(i in cities) {
weather_snow <- weather_history(i,
  start = "2017-12-01",
  end = "2023-12-01",
  daily = "snowfall_sum")

  weather_snow <- weather_snow %>% 
    rename(daily_snow = daily_snowfall_sum) #rename column
  weather_snow$city <- i # add city column
  weather_snow$year <- substr(weather_snow$date, 1,4) #create year column
  
  weather_snow <- weather_snow %>% 
    mutate(week = week(ymd(date))) %>% #add week column
    group_by(week) %>%  
    mutate(weekavg_snow = mean(daily_snow)) #compute weekly average daylight hours

  weather_snow <- weather_snow[, col_order_snow2] #reorder columns
  snow_dataframes[[i]] <- weather_snow #add new data frame to list
}

head(snow_dataframes)
```

```{r, include = FALSE}
#Combining city data

# Combine all city dataframes into one long dataframe
daylight_long <- bind_rows(daylight_dataframes)
head(daylight_long)

# Combine all city dataframes into one long dataframe
snow_long <- bind_rows(snow_dataframes)
head(snow_long)
```

These trends in daylight and snowfall were relatively stable over the five year period. The average daily daylight did not vary very much by year. While there was slightly more variation in snowfall by year, the average daily snowfall did not vary by more than 0.06 millimeters from year to year. Below is a snippet of the dataset after cleaning the data.

```{r, include = FALSE}
# Combining daylight and snowfall data
weather <- merge(daylight_long, snow_long, by = c("date", "week", "city"))
head(weather)
colnames(weather) 
```

```{r, echo=FALSE}
head(weather, n = 3)
```

### Google trends

In order to capture public interest in SAD-related indicators over time, Google search frequency trends data was obtained through the R package "gtrendsR" for December 1, 2017 to December 1, 2023 from the following cities to represent different parts of Michigan (excluding the Upper Peninsula): Ann Arbor, Detroit, Lansing, Grand Rapids, and Kalamazoo. We queried the keywords, "light therapy," "Seasonal Affective Disorder", and "winter blues". In addition to "SAD", we believed including one of its non-clinical names (winter blues) and a related popular remedy (light therapy) as key terms would help capture people's interests in SAD. We formatted the dataset so that the each row represented dates by weeks and columns represented keywords with search frequency in the cells. Below is a snippet of the datset. 

```{r, include=FALSE}
# google trends data

mich.trends <- read.csv("/Users/akarioya/temp/SURV727/Final Project/17_23_SearchFreqeuncies.csv", skip = 2) #allows third row to be column names
colnames(mich.trends)
```

```{r, include=FALSE}
# Clean gtrends whole Michigan data to match weather data
# Reorder date
mich.trends <- mich.trends %>% 
  mutate(date = as.Date(Week, format = "%m/%d/%y")) %>% 
  select(-c(Week)) %>% #remove old Week column
  mutate(year = substr(date, 1,4)) %>% 
  rename(light_therapy = light.therapy...Michigan.) %>% 
  rename(winter_blues = winter.blues...Michigan.) %>% 
  rename(SAD = Seasonal.affective.disorder...Michigan.) %>% 
  relocate(date, .before = light_therapy) #reorder columns

# Add week column that indicate number of weeks in year
mich.trends <- mich.trends %>% 
  mutate(week = week(ymd(date))) %>% 
  group_by(week)
```

```{r, echo=FALSE}
head(mich.trends)
```

```{r, include=FALSE}
# Combining whole Michigan gtrends data to weather data

weather_nd <- weather[, -1] #remove date column so data can merge smoothly

# Merge datasets based on variables
mich_df <- merge(mich.trends, weather_nd, by = c("week", "year"))
head(mich_df)
colnames(mich_df) 
```


# Analysis:

### Weather Data

We created interactive multi-line plots using the "plotly" and "ggplot2" packages in R. The key rationale behind the usage of these interactive data visualizations is to grant users the flexibility to explore and scrutinize the weather pattern within their desired time span more intimately. Because there are many data points, we believe an interactive tool makes navigating patterns easier in the data as well. We started with the '**Average Weekly Snowfall from 12/1/2017- 12/1/2023**' and '**Average Weekly Daylight from 12/1/2017- 12/1/2023**' to examine how snowfall pattern and daylight duration change throughout our selected period for selected cities in Michigan.

```{r, echo=FALSE, warning=FALSE}
library(ggplot2)
library(plotly)

p1 <- ggplot(data = weather, aes(x= date))+
  geom_line(aes(y = weekavg_snow, color = city)) +
  ggtitle("Average Weekly Snowfall 12/1/2017- 12/1/2023") + xlab("Week") + ylab("Snowfall (mm)") +
  theme(plot.title = element_text(hjust = 0.5))
  
# Create a ggplotly object from the ggplot object
p1 <- ggplotly(p1)

# Print the interactive plot
print(p1)

p2 <- ggplot(data = weather, aes(x= date))+
  geom_line(aes(y = weekavg_hrs, color = city)) +
  ggtitle("Average Weekly Daylight 12/1/2017- 12/1/2023") + xlab("Week") + ylab("Daylight (hours)") +
  theme(plot.title = element_text(hjust = 0.5))
  
# Create a ggplotly object from the ggplot object
p2 <- ggplotly(p2)

# Print the interactive plot
print(p2)
```


### Google Search Frequencies

We initially looked at interest by city data (shown below) after querying for data from the whole state of Michigan. "Light therapy" had the highest search frequency throughout the years. Peaks for each word seems to overlap during similar time frames, in the fall and winter months. 

```{r, echo=FALSE, eval=FALSE}
# For Google Trends data

# Query keywords
library(gtrendsR)
SADtrends <- gtrends(c("light therapy", "seasonal affective disorder", "winter blues"), 
               geo = "US-MI", 
               time = "2017-12-01 2023-12-01", 
               low_search_volume = TRUE)
```

```{r, include=FALSE, eval=FALSE}
# Save each dataset as CSV so we don't lose the data since we keep having issues with GTrends
# interest by city
trends_city <- SADtrends$interest_by_city
write.csv(rest_city, "SADtrends_interest_by_city.csv")

# interest over time
trends_time <- SADtrends$interest_over_time
write.csv(trends_time, "SADtrends_interest_over_time.csv")

# interest by dma (seems like certain big cities)
trends_dma <- SADtrends$interest_by_dma
write.csv(trends_dma, "SADtrends_interest_by_dma.csv")

# interest by dma (seems like certain big cities)
trends_related <- SADtrends$related_queries
write.csv(trends_related, "SADtrends_related_queries.csv")
```

```{r, include=FALSE}
# Read in CSV
trends_time <- read_csv("SADtrends_interest_over_time.csv")
trends_city <- read_csv("SADtrends_interest_by_city.csv")
```

```{r, echo=FALSE}
# Trends over time plot
trends_time %>% 
  ggplot(aes(x = date, y = hits)) + 
  geom_line(aes(y = hits, color = keyword)) +
  ggtitle("Search Frequencies between 2018-2023") + xlab("Date") + ylab("Hits Frequency")
```

```{r, include=FALSE}
# Examining interest over city data

# Reshape data so each keyword becomes a column and each row is a city
city_ranking <- trends_city %>%
  pivot_wider(names_from = keyword, 
              values_from = hits)
```

However, the state-wide data had a lot of missing data in search hits for our keywords. In particular, only the term "seasonal affective disorder" had search hits data.

```{r, echo=FALSE}
city_ranking %>% 
  arrange(desc(`seasonal affective disorder`)) %>% 
  head(n=5)
```

Therefore, we tried another method: query each major city separately. There is no manual available for geo codes of Michigan cities, but the URL on the Google Trends website after selecting city filters displays an embedded geo code. We used these codes to see more specific data could be queried (For example: https://trends.google.com/trends/explore?date=2017-12-01%202023-12-01&*geo=US-MI-540*&q=light%20therapy&hl=en-US). We were able to find data for major Michigan cities, although some of them were group together (i.e., GrandRapids, Kalamazoo, and BattleCreek had one geo code).

```{r, include=FALSE, eval = FALSE}
# Querying for Detroit only
detroit_trends <- gtrends(c("light therapy", "seasonal affective disorder", "winter blues"), 
               geo = "US-MI-505", # geo code for Detroit from gtrends website URL 
               time = "2017-12-01 2023-12-01", 
               low_search_volume = TRUE)
detroit_trends <- as_tibble(detroit_trends$interest_over_time) 
write.csv(detroit_trends, "SADtrends_Detroit.csv") # save as csv

head(detroit_trends$interest_over_time)
write.csv(detroit_trends$interest_over_time, "SADtrends_Detroit.csv") # save as csv
```

```{r, include=FALSE, eval=FALSE}
#Repeat with other cities (creating a loop gave me the connection error message)

# List of city geo codes taken from gtrends URL
# Lansing = "US-MI-551"
# Alpena = "US-MI-583" - did not have any data, excluded from final analysis
# Flint-Saginaw-BayCity = "US-MI-513"
# GrandRapids-Kalamazoo-BattleCreek = "US-MI-563"
# Marquette = "US-MI-553"
# Traverse City-Cadillac = "US-MI-540"

lansing_trends <- gtrends(c("light therapy", "seasonal affective disorder", "winter blues"), 
               geo = "US-MI-551",  
               time = "2017-12-01 2023-12-01", 
               low_search_volume = TRUE)
lansing_trends <- as_tibble(lansing_trends$interest_over_time) 
write.csv(lansing_trends, "SADtrends_Lansing.csv") # save as csv

flint_trends <- gtrends(c("light therapy", "seasonal affective disorder", "winter blues"), 
               geo = "US-MI-513",  
               time = "2017-12-01 2023-12-01", 
               low_search_volume = TRUE)
flint_trends <- as_tibble(flint_trends$interest_over_time)
write.csv(flint_trends, "SADtrends_Flint-Saginaw-BayCity.csv")

gr_trends <- gtrends(c("light therapy", "seasonal affective disorder", "winter blues"), 
               geo = "US-MI-563",  
               time = "2017-12-01 2023-12-01", 
               low_search_volume = TRUE)
gr_trends <- as_tibble(gr_trends$interest_over_time)
write.csv(gr_trends, "SADtrends_GrandRapids-Kalamazoo-BattleCreek.csv") # save as csv

marq_trends <- gtrends(c("light therapy", "seasonal affective disorder", "winter blues"), 
               geo = "US-MI-553",  
               time = "2017-12-01 2023-12-01", 
               low_search_volume = TRUE)
marq_trends <- as_tibble(marq_trends$interest_over_time)
write.csv(marq_trends, "SADtrends_Marquette.csv") # save as csv

trav_trends <- gtrends(c("light therapy", "seasonal affective disorder", "winter blues"), 
               geo = "US-MI-540",  
               time = "2017-12-01 2023-12-01", 
               low_search_volume = TRUE)
trav_trends <- as_tibble(trav_trends$interest_over_time)
write.csv(trav_trends, "SADtrends_Traverse City-Cadillac.csv") # save as csv

# Combine all into one dataset
SAD_bycity <- bind_rows(detroit_trends, lansing_trends, alpena_trends, flint_trends, gr_trends, marq_trends, trav_trends)
summary(SAD_bycity)
write.csv(SAD_bycity, "SADtrends_bycity.csv") # save as csv
```


```{r, include=FALSE}
# Load CSV data
SAD_bycity <- read_csv("SADtrends_bycity.csv")
```


```{r, include=FALSE}
# Clean data
SAD_bycity_grp <- SAD_bycity %>% 
  mutate(date = as.Date(date, format = "%Y-%m/%d")) %>% 
  select(-c(time, gprop, category)) %>% #remove unnecessary variables
  mutate(year = substr(date, 1,4)) %>% #create year variable
  mutate(month = substr(date,6,7)) %>% #create month variable  
  group_by(date, geo, year, month, keyword) %>%
  summarise(hits = sum(hits)) %>% 
  ungroup() %>% 
  rename(city = geo)

# Recode city values
SAD_bycity_grp$city <- recode(SAD_bycity_grp$city, 
                              "US-MI-505" = "Detroit",
                              "US-MI-551" = "Lansing",
                              "US-MI-513" = "Flint-Saginaw-Bay City",
                              "US-MI-563" = "Grand Rapids-Kalamazoo-Battle Creek",
                              "US-MI-553" = "Marquette",
                              "US-MI-540" = "Traverse City-Cadillac")

# Make keywords into columns with hits as values
SAD_bycity_grp <- SAD_bycity_grp %>%
  spread(key = keyword, value = hits)
head(SAD_bycity_grp)
```

Besides looking at the overall weather pattern across our time period of interest using interactive visualizations, we specifically looked at monthly frequencies for SAD-related search hits in 2018 using a static scatter plot to explore the monthly patterns in how people from different Michigan cities searched for SAD-related terms in 2018.

```{r, echo=FALSE, warning=FALSE}
SAD_bycity_grp %>% ggplot(aes(x= date)) +
  geom_point(aes(y = `light therapy`, color = "Light Therapy"), linewidth = 1.2)+
  geom_point(aes(y = `winter blues`, color = "Winter Blues"), linewidth = 1.2) +
  geom_point(aes(y = `seasonal affective disorder`, color = "Seasonal Affective Disorder"), linewidth = 1.2) + 
  scale_x_date(limits = as.Date(c("2018-01-01","2018-12-31"))) +
  ggtitle("Monthly freqeincies for SAD-related search hits in 2018") + xlab("Month") + ylab("Search hits")
```


### Weather Data + Google Search Frequencies
Finally, we created another interactive visualization through the "shiny" package in R. This interactive map is centered at the coordinates for Michigan and places city markers at locations based on longitude and latitude. When a user clicks on a marker, a popup will display with information about the date, city, average daylight, snowfall, and search frequencies for SAD-related terms.

The Shiny app is accessible at: <link>

```{r}
# First, add necessary info for Shiny 
# Add latitude and longitude conditionally based on the city
mich_df$latitude <- ifelse(mich_df$city == "Detroit", 42.3314,
                            ifelse(mich_df$city == "Ann Arbor", 42.2808,
                                   ifelse(mich_df$city == "Lansing", 42.7325,
                                          ifelse(mich_df$city == "Grand Rapids", 42.9634,
                                                 ifelse(mich_df$city == "Kalamazoo", 42.2917, NA)
                                          )
                                   )
                            )
)

mich_df$longitude <- ifelse(mich_df$city == "Detroit", -83.0458,
                             ifelse(mich_df$city == "Ann Arbor", -83.7430,
                                    ifelse(mich_df$city == "Lansing", -84.5555,
                                           ifelse(mich_df$city == "Grand Rapids", -85.6681,
                                                  ifelse(mich_df$city == "Kalamazoo", -85.5872, NA)
                                           )
                                    )
                             )
)
```

```{r, include=FALSE}
#Trying Shiny app

library(shiny)
library(rsconnect)
library(leaflet)

# Shiny UI
ui <- fluidPage(
  titlePanel("Interactive Map"),
  leafletOutput("map")
)

# Server
server <- function(input, output) {
  
  output$map <- renderLeaflet({
    leaflet() %>%
      addTiles() %>%
      setView(lng = -83.7430, lat = 44.3148, zoom = 7) %>%  # Coordinates for Michigan
      addMarkers(data = mich_df, ~longitude, ~latitude,
                 popup = paste("Date: ", mich_df$date, "<br>",
                               "City: ", mich_df$city, "<br>",
                               "Weather: ", mich_df$average_daily_daylight, " hours of daylight, ",
                               mich_df$average_daily_snow, " inches of snow", "<br>",
                               "Trends: Light Therapy - ", mich_df$light_therapy, ", ",
                               "SAD - ", mich_df$seasonal_affective_disorder, ", ",
                               "Winter Blues - ", mich_df$winter_blues))
  })
}

shinyApp(ui, server)
```

# Conclusion

### Findings



### Limitations

The current analysis has some limitations. One concern is unknown confounding variables that may play a large role in the relationship between daylight, snowfall, and changes in the public's interest of SAD-related topics reflected by Google search trends. It important to note that we adopted common terms assaociated with SAD as our search keys for Google trend, so it is not a comprehensive lists of SAD-related terms. Although some research [@hoang2011association] suggesting that vitamin D synthesis in the body from sunlight affects or improves one's mood has gained popularity in recent years, supporting our analysis of Google search trends and weather data, the intent behind users' searches are not clear. Furthermore, higher or lower search hits do not directly reflect the actual number of diagnoses or people experiencing SAD-related symptoms. Thus, we cannot make strong or holistic conclusions about the link between weather and increase in SAD interest or prevalence. 

A second limitation is the nature of the Google trends data. Search trend hits were aggregated by week while hourly data was available for weather. Higher granulated data of search hits may reveal different patterns. Moreover, search hit frequencies were low for many cities and days which lead to missing data. Different sets of keywords may have better success in gathering more data and uncovering different information, but the task of choosing the appropriate keywords is challenging. Since mood is a factor in the link between weather and SAD, an additional analysis such as a sentiment analysis of Internet users' mood over the year may provide more nuance in our conclusions.

# References

